{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of individual authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "from scipy.optimize import minimize_scalar\n",
    "from collections import defaultdict\n",
    "import scipy.special\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_file_path = '../../data/dblp/dblp.v12.json' # Path to the DBLP dataset (12th version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    id: int # ID of the article from DBLP\n",
    "    year: int # Year of publication\n",
    "    authors: list[int] # List of author IDs\n",
    "    references: list[int] # List of reference IDs\n",
    "    data_citations: int # Number of citations from DBLP\n",
    "    citations: list[Article] = field(default_factory=list) # List of citing articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Author:\n",
    "    id: int # ID of the author from DBLP\n",
    "    articles: list[Article] = field(default_factory=list) # List of articles written by the author\n",
    "    citation_events: list[tuple[Article, Article, int]] = field(default_factory=list) # List of citation events in the form (citing article, cited article, citation type)\n",
    "    log_likelihood_partial: list[tuple[float, ...]] = field(default_factory=list) # list of partial calculations for the log-likelihood\n",
    "    external_citations: int = 0 # Total number of external citations\n",
    "    self_citations: int = 0 # Total number of self-citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {} # Dictionary of articles indexed by their ID\n",
    "\n",
    "with open(dblp_file_path, encoding = 'utf8') as file:\n",
    "    for line in tqdm.tqdm(file, total = 4894083):\n",
    "        if line[0] == ',':\n",
    "            line = line[1:]\n",
    "        if line[0] != '{':\n",
    "            continue\n",
    "        \n",
    "        article_json = json.loads(line)\n",
    "\n",
    "        # Filter out articles that do not have the required fields\n",
    "        if 'authors' not in article_json or 'year' not in article_json or 'references' not in article_json or 'n_citation' not in article_json:\n",
    "            continue\n",
    "        \n",
    "        article_authors = [int(author['id']) for author in article_json['authors']]\n",
    "        article_id = int(article_json['id'])\n",
    "        article_year = int(article_json['year'])\n",
    "        article_references = [int(reference_id) for reference_id in article_json['references']]\n",
    "        article_ncitations = int(article_json['n_citation'])\n",
    "\n",
    "        article = Article(id = article_id, year = article_year, authors = article_authors, references = article_references, data_citations = article_ncitations)\n",
    "        articles[article_id] = article\n",
    "\n",
    "f'Number of articles: {len(articles)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_references = set() # Set of reference IDs that are not in the dataset\n",
    "                         # (i.e. filtered out in the previous step or missing)\n",
    "num_references = 0 # Total number of references\n",
    "num_empty_references = 0 # Number of references that are not in the dataset\n",
    "\n",
    "for article in tqdm.tqdm(articles.values()): # Recreate citations based on references\n",
    "    for reference_id in article.references:\n",
    "        if reference_id in articles:\n",
    "            articles[reference_id].citations.append(article)\n",
    "        else:\n",
    "            empty_references.add(reference_id)\n",
    "            num_empty_references += 1\n",
    "        num_references += 1\n",
    "\n",
    "f'Empty references: {100 * num_empty_references / num_references:.2f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = {} # Dictionary of authors indexed by their ID\n",
    "\n",
    "for article in tqdm.tqdm(articles.values()):\n",
    "    for author_id in article.authors:\n",
    "        if author_id not in authors:\n",
    "            authors[author_id] = Author(id = author_id)\n",
    "        authors[author_id].articles.append(article)\n",
    "\n",
    "f'Number of authors: {len(authors)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Recreate citation events - citation_type = 1 for self-citations, 0 for external citations  \n",
    "\n",
    "for author in tqdm.tqdm(authors.values()):\n",
    "    for article in author.articles:\n",
    "        for citing_article in article.citations:\n",
    "            citation_type = 1 if author.id in citing_article.authors else 0\n",
    "            if citation_type == 0:\n",
    "                author.external_citations += 1\n",
    "            else:\n",
    "                author.self_citations += 1\n",
    "            author.citation_events.append((article, citing_article, citation_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in tqdm.tqdm(authors.values()): # Sort articles and citation events by year\n",
    "    author.articles.sort(key = lambda article: article.year)\n",
    "    author.citation_events.sort(key = lambda event: event[1].year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_citation_vector(author):\n",
    "    \"\"\"A function that recreates the citation vector for an author\n",
    "    based on the number of citations in the citation network.\"\"\"\n",
    "    \n",
    "    citation_vector = np.array([len(article.citations) for article in author.articles])\n",
    "    return citation_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_citation_vector_filtered(author, filter_type):\n",
    "    \"\"\"A function that recreates the citation vector for an author\n",
    "    based on the number of citations in the citation network, with\n",
    "    a filter applied (0 - external, 1 - self-citations).\"\"\"\n",
    "    \n",
    "    citations = defaultdict(int)\n",
    "\n",
    "    for event in author.citation_events:\n",
    "        if event[0].year > event[1].year:\n",
    "            continue\n",
    "\n",
    "        if event[2] is not filter_type:\n",
    "            continue\n",
    "        \n",
    "        citations[event[0].id] += 1\n",
    "    \n",
    "    citations = [citations[article.id] for article in author.articles]\n",
    "\n",
    "    return np.array(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea is to calculate the probability of a citation event under\n",
    "# various models (here random and PAR) separately and then combine\n",
    "# them with different weights\n",
    "\n",
    "def model(published_articles, citation_event):\n",
    "    \"\"\"A function that calculates the probability of a citation event under\n",
    "    the random and preferential attachment models.\"\"\" \n",
    "    \n",
    "    published_articles_filtered = {article_id: citations for article_id, citations in published_articles.items() if article_id != citation_event[1].id}\n",
    "    random_dist = 1 / len(published_articles_filtered)\n",
    "    sum_citations = sum(published_articles_filtered.values())\n",
    "    preferential_dist = published_articles_filtered[citation_event[0].id] / sum(published_articles_filtered.values()) if sum_citations > 0 else 0\n",
    "    return np.array([random_dist, preferential_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partial_log_likelihood(author, model, filter_type = None, **kwargs):\n",
    "    \"\"\"A function that calculates the partial likelihood values for an author\"\"\"\n",
    "\n",
    "    published_articles = {}\n",
    "    last_year = None\n",
    "    last_year_dump = None\n",
    "\n",
    "    author.log_likelihood_partial.clear()\n",
    "\n",
    "    temp_citations = defaultdict(int)\n",
    "\n",
    "    for event in author.citation_events:\n",
    "        if event[0].year > event[1].year:\n",
    "            continue\n",
    "\n",
    "        if last_year_dump != event[1].year:\n",
    "            for article_id, count in temp_citations.items():\n",
    "                published_articles[article_id] += count\n",
    "            last_year_dump = event[1].year\n",
    "            temp_citations.clear()\n",
    "\n",
    "        if last_year != event[1].year:\n",
    "            for article in author.articles:\n",
    "                if article.year <= event[1].year and article.id not in published_articles:\n",
    "                    published_articles[article.id] = 0\n",
    "        last_year = event[1].year\n",
    "\n",
    "        if filter_type is None or event[2] == filter_type:\n",
    "            author.log_likelihood_partial.append(model(published_articles, event, **kwargs))\n",
    "        \n",
    "        temp_citations[event[0].id] += 1\n",
    "\n",
    "    for article_id, count in temp_citations.items():\n",
    "        published_articles[article_id] += count\n",
    "\n",
    "    return published_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partial_log_likelihood_all(authors, model, filter_type = None, **kwargs):\n",
    "    \"\"\"A function that calculates the partial likelihood values for all authors\"\"\"\n",
    "    \n",
    "    for author in tqdm.tqdm(authors.values()):\n",
    "        if len(author.articles) < 10 or len(author.citation_events) == 0:\n",
    "            continue\n",
    "        \n",
    "        calculate_partial_log_likelihood(author, model, filter_type, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(partials, weights):\n",
    "    \"\"\"A function that calculates the log-likelihood value for\n",
    "    a single citation event given set of partial values and weights\"\"\"    \n",
    "\n",
    "    return np.log(np.dot(partials, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood(author, weights):\n",
    "    \"\"\"A function that calculates the log-likelihood value for an author\n",
    "    given a set of weights\"\"\"\n",
    "    \n",
    "    log_likelihood = 0\n",
    "\n",
    "    for partials in author.log_likelihood_partial:\n",
    "        log_likelihood += log_prob(partials, weights)\n",
    "\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood_all(authors, weights):\n",
    "    \"\"\"A function that calculates the log-likelihood value for all authors\n",
    "    given a set of weights\"\"\"\n",
    "\n",
    "    log_likelihood = 0\n",
    "\n",
    "    for author in tqdm.tqdm(authors.values()):\n",
    "        for partials in author.log_likelihood_partial:\n",
    "            log_likelihood += log_prob(partials, weights)\n",
    "\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_model(author):\n",
    "    \"\"\"A function that maximizes the log-likelihood value for an author\n",
    "    and finds the optimal value of $\\rho$, that is 1 - $\\alpha$.\"\"\"\n",
    "\n",
    "    def f(alpha):\n",
    "        return -calculate_log_likelihood(author, np.array([alpha, 1-alpha]))\n",
    "    \n",
    "    result = minimize_scalar(f, bounds=(0.01, 0.99))\n",
    "    assert result.success\n",
    "\n",
    "    return result.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_partial_log_likelihood_all(authors, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = {} # Dictionary of results for all citations indexed by author ID\n",
    "for author in tqdm.tqdm(authors.values()):\n",
    "    if not hasattr(author, 'log_likelihood_partial') or len(author.log_likelihood_partial) == 0:\n",
    "        continue\n",
    "\n",
    "    results_all[author.id] = maximize_model(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_partial_log_likelihood_all(authors, model, filter_type = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_external = {} # Dictionary of results for external citations indexed by author ID\n",
    "for author in tqdm.tqdm(authors.values()):\n",
    "    if not hasattr(author, 'log_likelihood_partial') or len(author.log_likelihood_partial) == 0:\n",
    "        continue\n",
    "\n",
    "    results_external[author.id] = maximize_model(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_partial_log_likelihood_all(authors, model, filter_type = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_self = {} # Dictionary of results for self-citations indexed by author ID\n",
    "for author in tqdm.tqdm(authors.values()):\n",
    "    if not hasattr(author, 'log_likelihood_partial') or len(author.log_likelihood_partial) == 0:\n",
    "        continue\n",
    "\n",
    "    results_self[author.id] = maximize_model(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with 3DSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_log = lambda param, x, C, N: np.log((1.0-param[0])*C)+np.log(scipy.special.poch(x,-param[0])/scipy.special.poch(N+1,-param[0]) - 1.0)-np.log(N*param[0])\n",
    "\n",
    "def fit_model(x, y, model_log, param0, bounds, args=[], loss='cauchy'):\n",
    "    def resid(param, x, y, args):\n",
    "        return model_log(param, x, *args)-np.log(y)\n",
    "    \n",
    "    return scipy.optimize.least_squares(resid, param0, kwargs={\"x\": x, \"y\": y, \"args\": args},\n",
    "           bounds=bounds, loss=loss)\n",
    "\n",
    "results_3dsi = {}\n",
    "for author in tqdm.tqdm(authors.values()):\n",
    "    if not hasattr(author, 'log_likelihood_partial') or len(author.log_likelihood_partial) == 0:\n",
    "        continue\n",
    "    \n",
    "    _x = recreate_citation_vector(author)\n",
    "    _x = _x[_x > 0]\n",
    "    _x[::-1].sort()\n",
    "\n",
    "    res = fit_model(np.arange(1, len(_x)+1), _x, model3_log, [0.5], args=[_x.sum(), _x.shape[0]], bounds=([1e-6], [1-1e-6]), loss='cauchy')\n",
    "    assert res[\"success\"]\n",
    "\n",
    "    results_3dsi[author.id] = res[\"x\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_count = 0\n",
    "with open('results/model_random_par_citations_separate.csv', 'w') as file:\n",
    "    file.write(f'id,articles,citations,external_citations,self_citations,alpha_all,alpha_external,alpha_self,3dsi\\n')\n",
    "    for author in tqdm.tqdm(authors.values()):\n",
    "        if not hasattr(author, 'log_likelihood_partial') or len(author.log_likelihood_partial) == 0 or author.id not in results_all or author.id not in results_external or author.id not in results_self:\n",
    "            continue\n",
    "        \n",
    "        author_count += 1\n",
    "\n",
    "        file.write(f'{author.id},{len(author.articles)},{len(author.citation_events)},{author.external_citations},{author.self_citations},{results_all[author.id]},{results_external[author.id]},{results_self[author.id]},{results_3dsi[author.id]}\\n')\n",
    "\n",
    "f'Number of authors: {len(author_count)}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "source-CIEG2doJ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
